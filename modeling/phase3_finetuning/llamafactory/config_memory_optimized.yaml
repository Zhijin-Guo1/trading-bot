# Memory-optimized config for RTX 3090 (24GB)
# Prevents OOM errors during training

### Model ###
model_name_or_path: Qwen/Qwen2.5-1.5B-Instruct
trust_remote_code: true

### Method ###
stage: sft
do_train: true
finetuning_type: lora
lora_target: all

### LoRA ###
lora_rank: 32              # Reduced from 64 to save memory
lora_alpha: 64              # Reduced proportionally
lora_dropout: 0.1

### Data ###
dataset_dir: data
dataset: 8k_train
template: qwen
cutoff_len: 1024            # Reduced from 2048 to save memory
preprocessing_num_workers: 2
overwrite_cache: true

### Training ###
output_dir: ./outputs/qwen2.5-1.5b-lora
overwrite_output_dir: true
per_device_train_batch_size: 2     # Reduced from 8 to prevent OOM
gradient_accumulation_steps: 8     # Increased to maintain effective batch=16
num_train_epochs: 3
learning_rate: 5e-4
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true
gradient_checkpointing: true       # Enable to save memory
logging_steps: 10
save_steps: 100
save_total_limit: 2               # Reduced to save disk space
report_to: none
logging_dir: ./logs
optim: adamw_torch
max_grad_norm: 1.0

### Memory optimization ###
ddp_find_unused_parameters: false
dataloader_pin_memory: false      # Disable to save memory
dataloader_num_workers: 0         # Reduce to save memory